{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.reader(open(\"hepatitis_2_csv.csv\", \"r\"))\n",
    "x = list(reader)\n",
    "res = np.array(x).astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568\n"
     ]
    }
   ],
   "source": [
    "training_class_name=res[0:568,19:20];\n",
    "training_data=res[0:568,0:19];\n",
    "training_data=np.matrix(training_data)\n",
    "training_data=training_data.transpose()\n",
    "training_class_name=np.matrix(training_class_name)\n",
    "training_class_name=training_class_name.transpose()\n",
    "print(np.prod(list(training_class_name[0].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanData=training_data.mean()\n",
    "varianceData=np.var(training_data)\n",
    "training_data=(training_data-meanData)/varianceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self):\n",
    "        self.weights=[];\n",
    "        self.bias=[];\n",
    "        self.status=[];\n",
    "        self.a=[[]];\n",
    "        self.z=[[]];\n",
    "        self.da=[[]];\n",
    "        self.dz=[[]];\n",
    "        self.dw=[[]];\n",
    "        self.db=[[]];\n",
    "        self.cost=[];\n",
    "        self.trainingOutput=[];\n",
    "        self.correctOutput=[];\n",
    "        \n",
    "    def model(self,layers):\n",
    "        self.layers=layers\n",
    "        self.status.append(\"Model archetecture recieved\")\n",
    "        self.createBrain()\n",
    "        self.status.append(\"Model archetecture created\")\n",
    "        return self.layers\n",
    "    \n",
    "    def createBrain(self):\n",
    "        inputshape = self.layers[0].getshape()\n",
    "        self.weights.append(0.01*np.random.rand(self.layers[1].getparams()[\"noOfUnits\"],inputshape[0]))\n",
    "        self.bias.append(np.ones([self.layers[1].getparams()[\"noOfUnits\"],inputshape[1]]))\n",
    "        print(\"layer 1 has bias shape as {} and weights shape as {}\".format(self.bias[0].shape,self.weights[0].shape))\n",
    "        for i in range(2,len(self.layers)):\n",
    "            lowerlimit=self.layers[i].getparams()[\"noOfUnits\"]\n",
    "            upperlimit=self.layers[i-1].getparams()[\"noOfUnits\"]\n",
    "            self.weights.append(0.01*np.random.rand(lowerlimit,upperlimit))\n",
    "            self.bias.append(np.ones([lowerlimit,inputshape[1]]))\n",
    "            print(\"layer {} has bias shape as {} and weights shape as {}\".format(i,self.bias[i-1].shape,self.weights[i-1].shape))\n",
    "    \n",
    "    def train(self,epochs,traindata,trainoutcome,LearningRate):\n",
    "        self.epochs=np.asmatrix(np.arange(0,epochs,1))\n",
    "        numberOfExamples = np.prod(list(training_class_name[0].shape))\n",
    "        for i in range(0,epochs):\n",
    "            val = self.forewardProp(numberOfExamples,traindata,trainoutcome,i)\n",
    "            if(self.layers[1].getparams()[\"activation\"]==\"sigmoid\"):\n",
    "                val=val>=0.499\n",
    "            elif(self.layers[1].getparams()[\"activation\"]==\"tanh\" or self.layers[1].getparams()[\"activation\"]==\"relu\"):\n",
    "                val=val>=0\n",
    "            self.trainingOutput.append(val)\n",
    "            self.correctOutput.append(trainoutcome)\n",
    "            self.status.append(\"Foreward Propogation for epoch {} is completed\".format(i))\n",
    "            self.backwardProp(numberOfExamples,trainoutcome,LearningRate,i)\n",
    "            self.status.append(\"Backward Propogation for epoch {} is completed\".format(i))\n",
    "            self.da.append([])\n",
    "            self.dz.append([])\n",
    "            self.dw.append([])\n",
    "            self.db.append([])\n",
    "            self.a.append([])\n",
    "            self.z.append([])\n",
    "            \n",
    "        #self.trainingOutput=np.asarray(self.trainingOutput)\n",
    "        #self.correctOutput=np.asarray(self.correctOutput)\n",
    "        #self.dz=np.asarray(self.dz)\n",
    "        #self.dw=np.asarray(self.dw)\n",
    "        #self.db=np.asarray(self.db)\n",
    "        #self.da=np.asarray(self.da)\n",
    "\n",
    "    \n",
    "    def forewardProp(self,m,traindata,trainoutcome,iterno):\n",
    "        self.a[iterno].append(traindata)\n",
    "        #self.weights=np.asarray(self.weights)\n",
    "        #self.bias=np.asarray(self.bias)\n",
    "        z=np.dot(self.weights[0],traindata)+self.bias[0]\n",
    "        self.z[iterno].append(z)\n",
    "        \n",
    "        if(self.layers[1].getparams()[\"activation\"]==\"sigmoid\"):\n",
    "            self.a[iterno].append(self.sigmoid(z))\n",
    "        elif(self.layers[1].getparams()[\"activation\"]==\"tanh\"):\n",
    "            self.a[iterno].append(self.tanh(z))\n",
    "        elif(self.layers[1].getparams()[\"activation\"]==\"relu\"):\n",
    "            self.a[iterno].append(self.relu(z))\n",
    "            \n",
    "        cost=self.costfunc(m,traindata,trainoutcome,self.a[iterno][1])\n",
    "        cost=np.sum(cost)\n",
    "        #print(self.bias[0])\n",
    "        \n",
    "        for i in range(2,len(self.layers)):\n",
    "            z=np.dot(self.weights[i-1],self.a[iterno][i-1])+self.bias[i-1]\n",
    "            self.z[iterno].append(z)\n",
    "            if(self.layers[1].getparams()[\"activation\"]==\"sigmoid\"):\n",
    "                self.a[iterno].append(self.sigmoid(z))\n",
    "            elif(self.layers[1].getparams()[\"activation\"]==\"tanh\"):\n",
    "                self.a[iterno].append(self.tanh(z))\n",
    "            elif(self.layers[1].getparams()[\"activation\"]==\"relu\"):\n",
    "                self.a[iterno].append(self.relu(z))\n",
    "        \n",
    "            cost=cost+np.sum( self.costfunc(m,traindata,trainoutcome,self.a[iterno][i]) )\n",
    "        self.cost.append(cost)\n",
    "        #self.a[iterno] = self.a[iterno].reshape((1, len(self.layers)))\n",
    "        print(\"cost for epoch {} is {}\".format(iterno,self.cost[iterno]))\n",
    "\n",
    "            \n",
    "        return self.a[iterno][len(self.layers)-1]\n",
    "     \n",
    "    def costfunc(self,m,traindata,trainoutcome,res):\n",
    "        A1=np.multiply(trainoutcome,np.log(res))\n",
    "        A2=np.multiply((1-trainoutcome),np.log((1-res)))\n",
    "        cost=A1+A2\n",
    "        cost=np.sum(cost)\n",
    "        cost=(-1/m)*cost\n",
    "        return cost\n",
    "    \n",
    "    def backwardProp(self,m,trainoutcome,learningRate,iterno):\n",
    "        AL=self.a[iterno][len(self.layers)-1]\n",
    "        dAL= - ( np.divide(trainoutcome,AL) - np.divide(1-trainoutcome,1-AL) )\n",
    "        self.da[iterno].append(dAL);\n",
    "        for i in range(0,len(self.layers)-1): \n",
    "            sigmoidprime=self.sigmoid_Prime(self.z[iterno][len(self.layers)-2-i])\n",
    "            dz = np.multiply(dAL,sigmoidprime)\n",
    "            self.dz[iterno].append(dz)\n",
    "            dw = (1/m) * ( dz * ( self.a[iterno][len(self.layers)-2-i].transpose() ) )\n",
    "            self.dw[iterno].append(dw)\n",
    "            dz = np.array(dz)\n",
    "            db = (1/m)*np.sum(dz,axis=1,keepdims=True)\n",
    "            db = np.asmatrix(db)\n",
    "            dz = np.asmatrix(dz)\n",
    "            self.db[iterno].append(db)\n",
    "            dAL=(self.weights[len(self.layers)-2-i].transpose())*dz\n",
    "            self.da[iterno].append(dAL)\n",
    "            # Updating weights\n",
    "            #print(\"dw is {}\".format(dw))\n",
    "            #print(\"db is {}\".format(db))\n",
    "            self.weights[len(self.layers)-2-i] = self.weights[len(self.layers)-2-i] - learningRate*dw\n",
    "            self.bias[len(self.layers)-2-i] = self.bias[len(self.layers)-2-i] - learningRate*db\n",
    "            #print(\"bias are {}\".format(self.bias[len(self.layers)-2]))\n",
    "                \n",
    "    def sigmoid_Prime(self,value):\n",
    "        part1=self.sigmoid(value)\n",
    "        part2=1-(self.sigmoid(value))\n",
    "        return np.multiply( part1 , part2 )\n",
    "    \n",
    "    def tanh_Prime(self,value):\n",
    "        return 1-(self.tanh(value)*self.tanh(value))\n",
    "    \n",
    "    def relu_Prime(self,value):\n",
    "        return value>=0\n",
    "        \n",
    "    def results(self):\n",
    "        trainingOutput=np.asarray(self.trainingOutput)\n",
    "        correctOutput=np.asarray(self.correctOutput)\n",
    "        print(trainingOutput.shape,correctOutput.shape)\n",
    "        #print(self.correctOutput.shape,self.trainingOutput.shape)\n",
    "        ls=correctOutput - trainingOutput\n",
    "        loss=np.sum(ls,axis=1)\n",
    "        loss=loss/len(loss)\n",
    "        ac=np.sum(correctOutput==trainingOutput,axis=1)\n",
    "        accuracy=ac/len(self.correctOutput)\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(self.epochs.T,accuracy)\n",
    "        plt.title(\"Training Accuracy\")\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(self.epochs.T,loss)\n",
    "        plt.title(\"Training Loss\")\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        #print(\"Accuracy : {}\".format(accuracy[len(accuracy)-1]))\n",
    "        #print(\"loss : {}\".format(loss[len(loss)-1]))\n",
    "    \n",
    "    def sigmoid(self,X):\n",
    "        return 1/(1+np.exp(-X));\n",
    "\n",
    "    def tanh(self,X):\n",
    "        return np.tanh(X);\n",
    "\n",
    "    def relu(self,X):\n",
    "        return np.maximum(0, X);\n",
    "\n",
    "    def getActivation(self):\n",
    "        # plot the activation function using matplotlib library\n",
    "        cur_axes = plt.gca()\n",
    "        # to remove the x axis\n",
    "        cur_axes.axes.get_xaxis().set_visible(False)\n",
    "        rangex=np.linspace(-10, 10, 100)\n",
    "\n",
    "        if(self.activation==\"sigmoid\"):\n",
    "            plt.plot(rangex,self.sigmoid(rangex))\n",
    "        elif(self.activation==\"tanh\"):\n",
    "            plt.plot(rangex,self.tanh(rangex))\n",
    "        elif(self.activation==\"relu\"):\n",
    "            plt.plot(rangex,self.relu(rangex))\n",
    "            plt.title(\"activation function = \"+self.activation)\n",
    "        \n",
    "    class Layers:\n",
    "        \n",
    "        class InputLayer:\n",
    "            \n",
    "            def __init__(self,shape):\n",
    "                self.shape=shape\n",
    "                \n",
    "            def getshape(self):\n",
    "                return np.asarray(self.shape).transpose()\n",
    "        \n",
    "        class DenseLayer:\n",
    "            \n",
    "            def __init__(self,noOfUnits,activation):\n",
    "                self.params={\"activation\":activation,\"shape\":(noOfUnits,1),\"noOfUnits\":noOfUnits}\n",
    "                \n",
    "            def getparams(self):\n",
    "                return self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 has bias shape as (15, 568) and weights shape as (15, 19)\n",
      "layer 2 has bias shape as (10, 568) and weights shape as (10, 15)\n",
      "layer 3 has bias shape as (5, 568) and weights shape as (5, 10)\n",
      "layer 4 has bias shape as (4, 568) and weights shape as (4, 5)\n",
      "layer 5 has bias shape as (1, 568) and weights shape as (1, 4)\n"
     ]
    }
   ],
   "source": [
    "my_brain = Net()\n",
    "l1=Net.Layers.InputLayer(training_data.shape)\n",
    "l2=Net.Layers.DenseLayer(15 , activation=\"sigmoid\")\n",
    "l3=Net.Layers.DenseLayer(10 , activation=\"sigmoid\")\n",
    "l4=Net.Layers.DenseLayer(5 , activation=\"sigmoid\")\n",
    "l5=Net.Layers.DenseLayer(4 , activation=\"sigmoid\")\n",
    "l6=Net.Layers.DenseLayer(1 , activation=\"sigmoid\")\n",
    "archetecture = my_brain.model(\n",
    "    layers=[l1,l2,l3,l4,l5,l6]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for epoch 0 is 18.70278818312418\n",
      "cost for epoch 1 is 18.687032996346634\n",
      "cost for epoch 2 is 18.68356571931705\n",
      "cost for epoch 3 is 18.68251921327333\n",
      "cost for epoch 4 is 18.682136771903014\n",
      "cost for epoch 5 is 18.681976704793165\n",
      "cost for epoch 6 is 18.68190314990592\n",
      "cost for epoch 7 is 18.68186726986375\n",
      "cost for epoch 8 is 18.68184912184046\n",
      "cost for epoch 9 is 18.681839735738567\n",
      "cost for epoch 10 is 18.681834803881202\n",
      "cost for epoch 11 is 18.68183217254998\n",
      "cost for epoch 12 is 18.681830739657872\n",
      "cost for epoch 13 is 18.68182993396256\n",
      "cost for epoch 14 is 18.681829457310393\n",
      "cost for epoch 15 is 18.68182915350553\n",
      "cost for epoch 16 is 18.68182894055963\n",
      "cost for epoch 17 is 18.681828775391725\n",
      "cost for epoch 18 is 18.681828635352442\n",
      "cost for epoch 19 is 18.681828508530653\n"
     ]
    }
   ],
   "source": [
    "my_brain.train(10,training_data,training_class_name,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 568) (10, 1, 568)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=my_brain.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9)\n"
     ]
    }
   ],
   "source": [
    "a=np.matrix([1,2,3,4,5,6,7,8,9])\n",
    "print(a[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
